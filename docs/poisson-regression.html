<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Poisson Regression | An Introduction to Generalized Linear Models</title>
  <meta name="description" content="Generalized Linear Models for non-statistics graduate students" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Poisson Regression | An Introduction to Generalized Linear Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Generalized Linear Models for non-statistics graduate students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Poisson Regression | An Introduction to Generalized Linear Models" />
  
  <meta name="twitter:description" content="Generalized Linear Models for non-statistics graduate students" />
  

<meta name="author" content="Emma Grossman, Leah Marcus, Emily Palmer, Katherine Pulham, Andrew Rumments" />


<meta name="date" content="2021-03-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">GRMs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About this book</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#linear-models---a-kind-of-generalized-linear-model"><i class="fa fa-check"></i><b>2.1</b> Linear models - a kind of Generalized Linear Model</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#linear-assumptions"><i class="fa fa-check"></i><b>2.2</b> Assumptions of Linear Models</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#reframing-linear-model"><i class="fa fa-check"></i><b>2.3</b> Reframing Linear Models as Generalized Linear Models</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#what-happens-when-we-break-the-assumptions-of-linear-models"><i class="fa fa-check"></i><b>2.4</b> What happens when we break the assumptions of linear models</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#parameter-estimation"><i class="fa fa-check"></i><b>2.5</b> Parameter estimation</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#lms-and-glms-in-r"><i class="fa fa-check"></i><b>2.6</b> LMs and GLMs in R</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#definitions"><i class="fa fa-check"></i><b>2.7</b> Some definitions</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#conclusion"><i class="fa fa-check"></i><b>2.8</b> Conclusion</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#examples"><i class="fa fa-check"></i><b>2.9</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html"><i class="fa fa-check"></i><b>3</b> How are GLMs “different”?</a>
<ul>
<li class="chapter" data-level="3.1" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#introdution"><i class="fa fa-check"></i><b>3.1</b> Introdution</a></li>
<li class="chapter" data-level="3.2" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#assumptions-of-a-glm"><i class="fa fa-check"></i><b>3.2</b> Assumptions of a GLM</a></li>
<li class="chapter" data-level="3.3" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#framework"><i class="fa fa-check"></i><b>3.3</b> Framework</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#exponential-dispersion-models"><i class="fa fa-check"></i><b>3.3.1</b> Exponential Dispersion models</a></li>
<li class="chapter" data-level="3.3.2" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#properties-of-edms"><i class="fa fa-check"></i><b>3.3.2</b> Properties of EDMs</a></li>
<li class="chapter" data-level="3.3.3" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#linking-the-edm-to-the-explanatory-data"><i class="fa fa-check"></i><b>3.3.3</b> Linking the EDM to the explanatory data</a></li>
<li class="chapter" data-level="3.3.4" data-path="how-are-glms-different.html"><a href="how-are-glms-different.html#formal-definition-of-a-glm"><i class="fa fa-check"></i><b>3.3.4</b> Formal definition of a GLM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="linear.html"><a href="linear.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="linear.html"><a href="linear.html#a-good-example-of-simple-linear-regression"><i class="fa fa-check"></i><b>4.2</b> A “Good” Example of Simple Linear Regression</a></li>
<li class="chapter" data-level="4.3" data-path="linear.html"><a href="linear.html#a-bad-example-of-simple-linear-regression"><i class="fa fa-check"></i><b>4.3</b> A “Bad” Example of Simple Linear Regression</a></li>
<li class="chapter" data-level="4.4" data-path="linear.html"><a href="linear.html#summary"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#what-is-binomial-data"><i class="fa fa-check"></i><b>5.1</b> What is Binomial Data?</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#refresher-bernoulli-and-binomial"><i class="fa fa-check"></i><b>5.1.1</b> Refresher: Bernoulli and Binomial</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#representing-the-bernoulli-distribution"><i class="fa fa-check"></i><b>5.1.2</b> Representing the Bernoulli distribution</a></li>
<li class="chapter" data-level="5.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#representing-the-binomial-distribution"><i class="fa fa-check"></i><b>5.1.3</b> Representing the binomial distribution</a></li>
<li class="chapter" data-level="5.1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#what-does-a-bunch-of-binomial-data-look-like-then"><i class="fa fa-check"></i><b>5.1.4</b> What does a bunch of binomial data look like then?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#why-doesnt-ols-work-for-binomial-data"><i class="fa fa-check"></i><b>5.2</b> Why doesn’t OLS work for Binomial Data?</a></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#link-functions-we-can-use"><i class="fa fa-check"></i><b>5.3</b> Link functions we can use</a></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ed50"><i class="fa fa-check"></i><b>5.4</b> ED50</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>6</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="poisson-regression.html"><a href="poisson-regression.html#what-is-poisson-data"><i class="fa fa-check"></i><b>6.1</b> What is Poisson data?</a></li>
<li class="chapter" data-level="6.2" data-path="poisson-regression.html"><a href="poisson-regression.html#why-ordinary-least-squares-does-not-work-for-poisson-data"><i class="fa fa-check"></i><b>6.2</b> Why ordinary least squares does not work for Poisson data</a></li>
<li class="chapter" data-level="6.3" data-path="poisson-regression.html"><a href="poisson-regression.html#link-functions-for-poisson-glms"><i class="fa fa-check"></i><b>6.3</b> Link functions for Poisson GLM’s</a></li>
<li class="chapter" data-level="6.4" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-example"><i class="fa fa-check"></i><b>6.4</b> Poisson Example</a></li>
<li class="chapter" data-level="6.5" data-path="poisson-regression.html"><a href="poisson-regression.html#problems-of-overdispersion-and-solutions"><i class="fa fa-check"></i><b>6.5</b> Problems of overdispersion and solutions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Generalized Linear Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="poisson-regression" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Poisson Regression</h1>
<p>After learning about one type of GLM using Binomial data in the previous section, this chapter will explore another common type of data where GLMs are used - Poisson data.</p>
<div id="what-is-poisson-data" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> What is Poisson data?</h2>
<p>To begin, we will start with the types of Poisson data that you may come across. Poisson data occurs when there is a need to model counts. Count data appears often in real world applications, so modeling this data accurately is an important skill to have. The counts of events being modeled should be independent and the upper limit of the counts should be much greater than the majority of the counts - this limit may not even exist. Possion GLMs can also be used to model rates when a Binomial GLM would not be appropriate. This occurs when populations are large and the rate of occurance is very small, usually less than 1%. The Poisson distribution has probability function P(y|<span class="math inline">\(\mu\)</span>) = <span class="math inline">\(e^{-\mu}\mu^y/y!\)</span> for y = 0, 1, 2,… and <span class="math inline">\(\mu\)</span> &gt; 0.</p>
</div>
<div id="why-ordinary-least-squares-does-not-work-for-poisson-data" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Why ordinary least squares does not work for Poisson data</h2>
<p>Similar to other types of GLMs that you have seen previously, ordinary least squares (OLS) regression cannot be used for Poisson data. Count data violates the constant variance assumption of OLS because as the counts get smaller and approach 0, the variance of the response must decrease, and as the counts grow larger, the variance of the response will tend to increase. The normal distribution is also not adequate for modeling the random component of count data because counts are both non-negative and discrete. The Poisson distribution is a more suitable option to model count data.</p>
</div>
<div id="link-functions-for-poisson-glms" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Link functions for Poisson GLM’s</h2>
<p>The most common link function used for Poisson regression is the logrithmic link function because it guarentees that <span class="math inline">\(\mu\)</span> will be greater than 0. It also makes interpretation of the regression parameters more straightforward, since they are interpreted as having multiplicative effects. The systematic component of a Poisson GLM is <span class="math inline">\(\mu = e^{\beta_0 + \beta_1x_1 + ... + \beta_px_p}\)</span> and increasing <span class="math inline">\(x_j\)</span> by one will increase <span class="math inline">\(\mu\)</span> by a factor of <span class="math inline">\(\beta_j\)</span>. Other link functions, while less commmon, can be used for a Poisson GLM. The identity link function, where <span class="math inline">\(\eta = \mu\)</span>, or the sqrt link function, where <span class="math inline">\(\eta = \sqrt{\mu}\)</span>, are two additional options. When all of the explanatory variables are quantitative, the data are modeled by a Poisson regression model using one of the three previous link functions. Additionally, quantile residuals should be used to asses the model fit since the data are discrete. Count data can also be represented in contingency tables so that observations can be cross-classified in their respective categories. These data are modeled using a log-linear model, where all of the explanatory variables are qualitative.</p>
</div>
<div id="poisson-example" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Poisson Example</h2>
<p><img src="images/bsb.jpg" /></p>
<p>Now that we have had a chance to go over some of the characteristics of Poisson GLMs, let’s look at an example involving baseball data. The dataset that we will use is a subset of data from the Lahman package, which is an extensive collection of baseball statistics since the 1800s. This package is an excellant resource for fellow baseball fans to practice fitting various GLM models, including Binomial regressions. The dataset that we will be focusing on is the batting statistics from every World Series during the liveball era. If you do not have the following packages, please take a moment to install them using the install.packages command. To start, we will need to load the Lahman package and the tidyverse package to access our World Series data, which is a subset of the Postseason dataset:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="poisson-regression.html#cb29-1"></a><span class="kw">require</span>(Lahman)</span></code></pre></div>
<pre><code>## Loading required package: Lahman</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="poisson-regression.html#cb31-1"></a><span class="kw">require</span>(tidyverse)</span>
<span id="cb31-2"><a href="poisson-regression.html#cb31-2"></a><span class="kw">data</span>(BattingPost)</span></code></pre></div>
<p>Now we can manipulate the data to focus only on the World Series batting statistics from the liveball era:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="poisson-regression.html#cb32-1"></a>liveball_ws &lt;-<span class="st"> </span>BattingPost <span class="op">%&gt;%</span></span>
<span id="cb32-2"><a href="poisson-regression.html#cb32-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1920</span>) <span class="op">%&gt;%</span></span>
<span id="cb32-3"><a href="poisson-regression.html#cb32-3"></a><span class="st">  </span><span class="kw">filter</span>(round <span class="op">==</span><span class="st"> &quot;WS&quot;</span>)</span></code></pre></div>
<p>Our response variable is going to be the runs scored by each player during each World Series from the liveball era. Initially, we can imagine that this will be a good canidate for Poisson regresssion because runs are a quantitative count. The number of runs scored by each player is also probably 0 to 1 typically, but there will be cases where a higher number of runs are occasionally scored and technically there is no upper limit to how many runs that is. Let’s graph the response variable and see if this seems to be the case:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="poisson-regression.html#cb33-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> liveball_ws, <span class="kw">aes</span>(<span class="dt">x =</span> R)) <span class="op">+</span></span>
<span id="cb33-2"><a href="poisson-regression.html#cb33-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb33-3"><a href="poisson-regression.html#cb33-3"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Runs Scored&quot;</span>) <span class="op">+</span></span>
<span id="cb33-4"><a href="poisson-regression.html#cb33-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Runs Scored During the World Series&quot;</span>, </span>
<span id="cb33-5"><a href="poisson-regression.html#cb33-5"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Live Ball Era&quot;</span>) <span class="op">+</span></span>
<span id="cb33-6"><a href="poisson-regression.html#cb33-6"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>)) </span></code></pre></div>
<p><img src="Bookdown_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>This indeed looks like a great candidate for Poisson regression. We could even imagine overlaying a Poisson distribution with a <span class="math inline">\(\mu\)</span> parameter of about 1 and see that it follows our response variable well. In fact, the mean number of runs scored in this dataset is 1.04, which would be the estimated <span class="math inline">\(\mu\)</span> value. Let’s now fit a model using batting-related outcome variables as our explanatory variables. We will model runs scored using the number of hits, doubles, triples, and home runs a player recored in each World Series:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="poisson-regression.html#cb34-1"></a>runmod &lt;-<span class="st"> </span><span class="kw">glm</span>(R <span class="op">~</span><span class="st"> </span>H <span class="op">+</span><span class="st"> </span>X2B <span class="op">+</span><span class="st"> </span>X3B <span class="op">+</span><span class="st"> </span>HR, <span class="dt">data =</span> liveball_ws, <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>)</span>
<span id="cb34-2"><a href="poisson-regression.html#cb34-2"></a><span class="kw">summary</span>(runmod)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = R ~ H + X2B + X3B + HR, family = &quot;poisson&quot;, data = liveball_ws)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.7850  -0.8260  -0.8260   0.4824   3.8405  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.075579   0.027460 -39.170  &lt; 2e-16 ***
## H            0.253262   0.005771  43.884  &lt; 2e-16 ***
## X2B          0.044604   0.017234   2.588  0.00965 ** 
## X3B          0.087291   0.036760   2.375  0.01757 *  
## HR           0.266188   0.015666  16.991  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 9503.5  on 4279  degrees of freedom
## Residual deviance: 4161.1  on 4275  degrees of freedom
## AIC: 8949.7
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>All of the variables here are significant at the standard .05 significance level, so they are all important for modeling the number of runs scored. Another point of interest to note from the model summary output is that the residual deviance of 4119 is smaller than its degress of freedom 4225 and much smaller than the null deviance of 9383. We will discuss why we should look at the residual deviance versus its degrees of freedom in the next section, but for now, the key takeaway is that the Poisson distribution was a good choice to model our data. Additionally, compared to our higher null deviance, our model does a good job of explaining the variability of runs scored. If baseball is a topic that interests you, I would encourage you to download the Lahman package and see if you can improve on this model by lowering the AIC.</p>
</div>
<div id="problems-of-overdispersion-and-solutions" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Problems of overdispersion and solutions</h2>
<p>A characteristic of the Poisson distribution is that the mean <span class="math inline">\(\mu\)</span> equals the variance. However, when modeling real data, this assumption can be a bit <span class="math inline">\({fishy}\)</span>, since the variance is usually greater than <span class="math inline">\(\mu\)</span>, resulting in overdispersion. Overdispersion occurs because the events being counted have a positive correlation and are not completely independent. We did not have to worry about overdispersion in our previous example, but you will likely come across it in other datasets. Overdispersion is an issue for Poisson GLMs because the standard errors of the <span class="math inline">\(\beta_j\)</span> estimates will be underestimated, making the model’s explanatory variables appear more significant than they actually are. Models fit using the Poisson family can be checked for overdispersion by comparing the residual deviance to the residual degrees of freedom. If the residual deviance is greater than the degrees of freedom, the model is overdispersed, and if the residual deviance is much less than the degrees of freedom, the model is underdispersed, a less frequent occurence. A large residual deviance compared to the residual degrees of freedom could also indicate a lack of fit, but this can be checked by eliminating outliers and fitting the model with the most explanatory variables possible. The residual deviance will still be large if overdispersion is the issue. Similarly, the Pearson goodness-of-fit statistic can be compared to the residual degrees of freedom to check for overdispersion. If the counts are small, so asymptotic approximations might not be accurate, large goodness-of-fit statistics generally indicate a poor model fit.</p>
<p>If there is overdispersion after fitting a Poisson GLM, the model can be fit using other related families. By modeling the data using a hierarchical model to add more variability, <span class="math inline">\(\mu\)</span> can be treated as a random variable, resulting in the response variable of interest following a negative binomial distribution. The expectation of <span class="math inline">\(y_i\)</span> is <span class="math inline">\(\mu_i\)</span> and the variance of <span class="math inline">\(y_i\)</span> is now <span class="math inline">\(\mu_i + \psi\mu_i^2\)</span>, where <span class="math inline">\(\psi\mu_i^2\)</span> is the added overdispersion term and <span class="math inline">\(\psi\)</span> is larger when overdispersion is greater. The MASS package contains the function glm.nb() to model negative binomial GLMs. The standard link function is the log-link function so that <span class="math inline">\(\mu\)</span> &gt; 0, and similar to the Poisson GLM, quantile residuals should be used. Quasi-Poisson models are another alternative to Poisson GLMs when there is overdispersion. The variance of <span class="math inline">\(y_i\)</span> is now <span class="math inline">\(\phi\mu_i\)</span>, where <span class="math inline">\(\phi\)</span> &gt; 1 represents overdispersion and raises standard errors to a factor of <span class="math inline">\(\sqrt{\phi}\)</span>. Quasi-Poisson models can be fit in R by family = quasipoisson() using the usual glm function. Quantile residuals cannot be found because the quasi-Poisson model is not a probability model but standardized deviance residuals can be examoned.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown.pdf", "Bookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
