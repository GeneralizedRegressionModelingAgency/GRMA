<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Introduction | An Introduction to Generalized Linear Models</title>
  <meta name="description" content="This is a draft of the book that we will write for non-Statisticians to understand GRMS" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Introduction | An Introduction to Generalized Linear Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a draft of the book that we will write for non-Statisticians to understand GRMS" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Introduction | An Introduction to Generalized Linear Models" />
  
  <meta name="twitter:description" content="This is a draft of the book that we will write for non-Statisticians to understand GRMS" />
  

<meta name="author" content="Emma Grossman, Leah Marcus, Emily Palmer, Katherine Pulham, Andrew Rumments" />


<meta name="date" content="2021-03-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="glms-kat.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">GRMs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Description of our book</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-came-before---linear-models"><i class="fa fa-check"></i><b>2.1</b> What came before - Linear models</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#some-definitions"><i class="fa fa-check"></i><b>2.2</b> Some definitions</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#assumptions-of-linear-models"><i class="fa fa-check"></i><b>2.3</b> Assumptions of linear models</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#what-happens-when-we-break-the-assumptions-of-linear-models"><i class="fa fa-check"></i><b>2.4</b> What happens when we break the assumptions of linear models</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#random-and-systematic-component"><i class="fa fa-check"></i><b>2.5</b> Random and Systematic Component</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#random-and-systematic-components-for-binary-and-count-data"><i class="fa fa-check"></i><b>2.6</b> Random and Systematic components for Binary and Count data</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#parameter-estimation"><i class="fa fa-check"></i><b>2.7</b> Parameter estimation</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#conclusion"><i class="fa fa-check"></i><b>2.8</b> Conclusion</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#examples"><i class="fa fa-check"></i><b>2.9</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="glms-kat.html"><a href="glms-kat.html"><i class="fa fa-check"></i><b>3</b> GLMs - Kat</a></li>
<li class="chapter" data-level="4" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>4</b> Linear Models - Emma</a>
<ul>
<li class="chapter" data-level="4.1" data-path="linear.html"><a href="linear.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression-andrew.html"><a href="logistic-regression-andrew.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression - Andrew</a></li>
<li class="chapter" data-level="6" data-path="poisson-glms-leah.html"><a href="poisson-glms-leah.html"><i class="fa fa-check"></i><b>6</b> Poisson GLMs - Leah</a></li>
<li class="chapter" data-level="7" data-path="learnr-test.html"><a href="learnr-test.html"><i class="fa fa-check"></i><b>7</b> LearnR test</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Generalized Linear Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Introduction</h1>
<div id="what-came-before---linear-models" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> What came before - Linear models</h2>
<p>If you are reading this book, you might already be familiar with linear models. Given our data, if we make some key assumptions (which we will explain later), we can perform either inference or prediction by assuming that our response value forms a linear relationship with our explanatory variable (or variables)</p>
<p>The reasoning of linear models is often intuitive, if we make a scatterplot our data, and see this:</p>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.3     ✓ purrr   0.3.4
## ✓ tibble  3.0.6     ✓ dplyr   1.0.4
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p><img src="Bookdown_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>we might want to fit a straight line through the cloud of points, i.e. modeling the relationship linearly.</p>
<p><img src="Bookdown_files/figure-html/lineplot-1.png" width="672" /></p>
<p>To interpret this relationship and make predictions, we need to know the slope and intercept of this line. This is done by minimizing the least squares, which will be explored in chapter 3 @ref{linear}.</p>
<p><img src="images/put_a_bird.png" style="width:50.0%" /></p>
</div>
<div id="some-definitions" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Some definitions</h2>
<p>Predictor - the thing on the y-axis
Explanatory variable - the stuff on the x-axis. Note that we can have more than one (but won’t plot it then), and then this becomes multivariate regression.</p>
<p>Something that is an estimated quantity will have a hat over it.
For example, we might assume that there is some ‘true’ (but unknown) linear relationship between our explanatory variables and our predictor.</p>
<p><span class="math display">\[ y = \beta_0 + \beta_1 x\]</span></p>
<p>From our sample data, we use a linear model to make an estimate of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>,</p>
<p>so our estimate/best guess of this true model relationship is</p>
<p><span class="math display">\[ \hat y = \hat\beta_0 + \hat\beta_1 x\]</span>
We of course want our <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span> to be a ‘good’ and ‘close’ estimate of the unknown quantities <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Ideas of what ‘good’ and ‘close’ mean will be covered in the next section.</p>
</div>
<div id="assumptions-of-linear-models" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Assumptions of linear models</h2>
<p>A linear model might very well be a good model if our data look like <a href="#fig:lineplot"><strong>??</strong></a>. However, there are many cases where it might be inappropriate to use a linear model. To understand these cases, we first review the assumptions of linear models.</p>
<p>Linear models assume:</p>
<ul>
<li>The relationship between the explanatory variables and the response is linear</li>
<li>The samples are independent.</li>
<li>The errors are normally distributed with mean 0 and constant variance</li>
</ul>
<p>We can write these assumptions down in notation as such.</p>
<p><span class="math display">\[y_i  = \beta_0 + \beta_1 x + \epsilon_i \]</span>
where
<span class="math display">\[ \epsilon_i \sim \text{iid } N(0,\sigma^2)\]</span>
In words, this means that each
this means that the errors are independent and identically distributed by the normal distribution, with mean 0 and constant variance <span class="math inline">\(\sigma^2\)</span> (notice how there is no subscript <span class="math inline">\(i\)</span> for the variance)</p>
<p>If these assumptions hold, we then write our model as
<span class="math display">\[ \hat y_i = \hat\beta_0 + \hat\beta_1 x_i\]</span></p>
<p>How can we tell when these assumptions are violated?</p>
<ul>
<li>Knowledge of the data.</li>
<li>Plots</li>
</ul>
</div>
<div id="what-happens-when-we-break-the-assumptions-of-linear-models" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> What happens when we break the assumptions of linear models</h2>
<p>Linear models are generally robust, and can be reasonable when assumptions are not exactly met. However, if we know assumptions are not met, and how they are not met, it is appropriate to use a more appropriate model for the data.</p>
</div>
<div id="random-and-systematic-component" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Random and Systematic Component</h2>
<p>We will now analyze the assumptions for linear models and explore how we can generalize them. (and create generalized linear models!)</p>
<p><span class="math display">\[y_i  = \beta_0 + \beta_1 x + \epsilon_i \]</span>
<span class="math display">\[ \epsilon_i \sim \text{iid } N(0,\sigma^2)\]</span></p>
<p>We refer to the first equation as the Systematic Component, and the second equation as the Random Component.</p>
<p>A Generalized Regression Model has a systematic component:</p>
<p><span class="math display">\[ g(y_i) = \beta_0 + \beta_1 x + \epsilon_i\]</span>
To generalized the systematic component, we use a link function <span class="math inline">\(g(y)\)</span>, so we now require some function of the response to be linearly related to our explanatory variables.</p>
<p>and a random component:</p>
<p><span class="math display">\[ \epsilon_i \sim \text{ iid } EDM(\phi) \]</span>
In words, the errors are independently distributed according to some probability distribution in the Exponential Dispersion Family, which will be discussed in the next chapter. Normal, Binomial, and Poisson distributions all fall into this family.</p>
<p>We note that normal linear models fall exactly into this framework, where <span class="math inline">\(g(y_i) = y_i\)</span> the identity function, and use the Normal distribution as our random component.</p>
<p>Deciding on what Random and Systematic component to use requires u</p>
</div>
<div id="random-and-systematic-components-for-binary-and-count-data" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Random and Systematic components for Binary and Count data</h2>
<p>The two most common cases of GRMs are those for Binary and Count data</p>
<p>For Binary data, the systemtatic component is, and the random component is: We call these types of GRMS logistic regression or …</p>
<p>For Count data, the systematic component is, and the random component is. We call these types of GRMS</p>
</div>
<div id="parameter-estimation" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Parameter estimation</h2>
<p>The last difference between linear models and generalized linear models is the way we estimate the parameters <span class="math inline">\(\beta\)</span>.</p>
</div>
<div id="conclusion" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Conclusion</h2>
<p>Linear models are not always the best tool for describing relationship in data. Luckily we can generalize the ideas and framework developed in linear models to hold for more general cases to create GLMs. Using a more general framework and more general assumptions allows us to build tools that will hold for all GRMs. The most notable of these that we will further explore are GRMs for binary data (ch4) and count data (ch5)</p>
</div>
<div id="examples" class="section level2" number="2.9">
<h2><span class="header-section-number">2.9</span> Examples</h2>
<p>Perhaps some examples of data and students can tell what type of data it should be modeled by?</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glms-kat.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown.pdf", "Bookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
